{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-sTsDfIVKsmL"
   },
   "source": [
    "# DAT405/DIT407 Introduction to Data Science and AI \n",
    "## 2022-2023, Reading Period 4\n",
    "## Assignment 4: Spam classification using Naïve Bayes \n",
    "The exercise takes place in this notebook environment.\n",
    "Hints:\n",
    "You can execute certain linux shell commands by prefixing the command with `!`. You can insert Markdown cells and code cells. The first you can use for documenting and explaining your results the second you can use writing code snippets that execute the tasks required.  \n",
    "\n",
    "In this assignment you will implement a Naïve Bayes classifier in Python that will classify emails into spam and non-spam (“ham”) classes.  Your program should be able to train on a given set of spam and “ham” datasets. \n",
    "You will work with the datasets available at https://spamassassin.apache.org/old/publiccorpus/. There are three types of files in this location: \n",
    "-\teasy-ham: non-spam messages typically quite easy to differentiate from spam messages. \n",
    "-\thard-ham: non-spam messages more difficult to differentiate \n",
    "-\tspam: spam messages \n",
    "\n",
    "**Execute the cell below to download and extract the data into the environment of the notebook -- it will take a few seconds.** If you chose to use Jupyter notebooks you will have to run the commands in the cell below on your local computer, with Windows you can use \n",
    "7zip (https://www.7-zip.org/download.html) to decompress the data.\n",
    "\n",
    "**What to submit:** \n",
    "Convert the notebook to a pdf-file and submit it. Make sure all cells are executed so all your code and its results are included. Double check the pdf displays correctly before you submit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Wa37fBwRF-xe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-24 08:20:52--  https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1677144 (1,6M) [application/x-bzip2]\n",
      "Saving to: ‘20021010_easy_ham.tar.bz2.1’\n",
      "\n",
      "20021010_easy_ham.t 100%[===================>]   1,60M  --.-KB/s    in 0,08s   \n",
      "\n",
      "2023-04-24 08:20:52 (19,2 MB/s) - ‘20021010_easy_ham.tar.bz2.1’ saved [1677144/1677144]\n",
      "\n",
      "--2023-04-24 08:20:52--  https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1021126 (997K) [application/x-bzip2]\n",
      "Saving to: ‘20021010_hard_ham.tar.bz2.1’\n",
      "\n",
      "20021010_hard_ham.t 100%[===================>] 997,19K  --.-KB/s    in 0,08s   \n",
      "\n",
      "2023-04-24 08:20:52 (11,8 MB/s) - ‘20021010_hard_ham.tar.bz2.1’ saved [1021126/1021126]\n",
      "\n",
      "--2023-04-24 08:20:52--  https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132, 2a04:4e42::644\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1192582 (1,1M) [application/x-bzip2]\n",
      "Saving to: ‘20021010_spam.tar.bz2.1’\n",
      "\n",
      "20021010_spam.tar.b 100%[===================>]   1,14M  --.-KB/s    in 0,07s   \n",
      "\n",
      "2023-04-24 08:20:52 (15,7 MB/s) - ‘20021010_spam.tar.bz2.1’ saved [1192582/1192582]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Download and extract data\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
    "!tar -xjf 20021010_easy_ham.tar.bz2\n",
    "!tar -xjf 20021010_hard_ham.tar.bz2\n",
    "!tar -xjf 20021010_spam.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdH1XTepLjZ3"
   },
   "source": [
    "*The* data is now in the three folders `easy_ham`, `hard_ham`, and `spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "A53Gw00fBLG2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7,8M\n",
      "drwxrwxr-x 5 hannes hannes 4,0K Apr 24 08:20 .\n",
      "drwxrwxr-x 8 hannes hannes 4,0K Apr 23 12:24 ..\n",
      "-rw-rw-r-- 1 hannes hannes 1,6M Jun 29  2004 20021010_easy_ham.tar.bz2\n",
      "-rw-rw-r-- 1 hannes hannes 1,6M Jun 29  2004 20021010_easy_ham.tar.bz2.1\n",
      "-rw-rw-r-- 1 hannes hannes 998K Dec 16  2004 20021010_hard_ham.tar.bz2\n",
      "-rw-rw-r-- 1 hannes hannes 998K Dec 16  2004 20021010_hard_ham.tar.bz2.1\n",
      "-rw-rw-r-- 1 hannes hannes 1,2M Jun 29  2004 20021010_spam.tar.bz2\n",
      "-rw-rw-r-- 1 hannes hannes 1,2M Jun 29  2004 20021010_spam.tar.bz2.1\n",
      "drwx--x--x 2 hannes hannes 180K Oct 10  2002 easy_ham\n",
      "drwx--x--x 2 hannes hannes  20K Dec 16  2004 hard_ham\n",
      "-rw-rw-r-- 1 hannes hannes  26K Apr 24 08:20 IDSAI_Assignment4_SP4_22-23.ipynb\n",
      "-rw-rw-r-- 1 hannes hannes 7,5K Apr 23 12:29 na‹ve_bayes_intro.ipynb\n",
      "-rw-rw-r-- 1 hannes hannes  11K Apr 23 12:29 probability_intro.ipynb\n",
      "drwxr-xr-x 2 hannes hannes  36K Oct 10  2002 spam\n"
     ]
    }
   ],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "DGlWPVnSNzT7"
   },
   "source": [
    "### 1. Preprocessing: \n",
    "\n",
    "##### 1.1 Look at a few emails from easy_ham, hard_ham and spam. Do you think you would be able to classify the emails just by inspection? How do you think a succesful model can learn the difference between the different classes of emails?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching text from a file path and removing the header info\n",
    "def fetch_format(path):\n",
    "   with open(path, 'r', encoding='latin1') as f:\n",
    "      split = f.read().split('\\n\\n', 1)\n",
    "   if len(split) == 1:\n",
    "      return split[0]\n",
    "   return split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "J2sllUWXKblD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've been running hammie on all my incoming messages, and I noticed that\n",
      "multipart/alternative messages are totally hosed: they have no content,\n",
      "just the MIME boundaries.  For instance, the following message:\n",
      "\n",
      "------------------------------8<------------------------------\n",
      "From: somebody <someone@somewhere.org>\n",
      "To: neale@woozle.org\n",
      "Subject: Booga\n",
      "Content-type: multipart/alternative; boundary=\"snot\"\n",
      "\n",
      "This is a multi-part message in MIME format.\n",
      "\n",
      "--snot\n",
      "Content-type: text/plain; charset=iso-8859-1\n",
      "Content-transfer-encoding: 7BIT\n",
      "\n",
      "Hi there.\n",
      "--snot\n",
      "Content-type: text/html; charset=iso-8859-1\n",
      "Content-transfer-encoding: 7BIT\n",
      "\n",
      "<pre>Hi there.</pre>\n",
      "--snot--\n",
      "------------------------------8<------------------------------\n",
      "\n",
      "Comes out like this:\n",
      "\n",
      "------------------------------8<------------------------------\n",
      "From: somebody <someone@somewhere.org>\n",
      "To: neale@woozle.org\n",
      "Subject: Booga\n",
      "Content-type: multipart/alternative; boundary=\"snot\"\n",
      "X-Hammie-Disposition: No; 0.74; [unrelated gar removed]\n",
      "\n",
      "This is a multi-part message in MIME format.\n",
      "\n",
      "--snot\n",
      "\n",
      "--snot--\n",
      "------------------------------8<------------------------------\n",
      "\n",
      "I'm using \"Python 2.3a0 (#1, Sep  9 2002, 22:56:24)\".\n",
      "\n",
      "I've fixed it with the following patch to Tim's tokenizer, but I have to\n",
      "admit that I'm baffled as to why it works.  Maybe there's some subtle\n",
      "interaction between generators and lists that I can't understand.  Or\n",
      "something.  Being as I'm baffled, I don't imagine any theory I come up\n",
      "with will be anywhere close to reality.\n",
      "\n",
      "In any case, be advised that (at least for me) hammie will eat\n",
      "multipart/alternative messages until this patch is applied.  The patch\n",
      "seems rather bogus though, so I'm not checking it in, in the hope that\n",
      "there's a better fix I just wasn't capable of discovering :)\n",
      "\n",
      "------------------------------8<------------------------------\n",
      "Index: tokenizer.py\n",
      "===================================================================\n",
      "RCS file: /cvsroot/spambayes/spambayes/tokenizer.py,v\n",
      "retrieving revision 1.15\n",
      "diff -u -r1.15 tokenizer.py\n",
      "--- tokenizer.py\t10 Sep 2002 18:15:49 -0000\t1.15\n",
      "+++ tokenizer.py\t11 Sep 2002 05:01:16 -0000\n",
      "@@ -1,3 +1,4 @@\n",
      "+#! /usr/bin/env python\n",
      " \"\"\"Module to tokenize email messages for spam filtering.\"\"\"\n",
      " \n",
      " import email\n",
      "@@ -507,7 +508,8 @@\n",
      "             htmlpart = textpart = None\n",
      "             stack = part.get_payload()\n",
      "             while stack:\n",
      "-                subpart = stack.pop()\n",
      "+                subpart = stack[0]\n",
      "+                stack = stack[1:]\n",
      "                 ctype = subpart.get_content_type()\n",
      "                 if ctype == 'text/plain':\n",
      "                     textpart = subpart\n",
      "------------------------------8<------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code for here for looking a few emails\n",
    "import os, random\n",
    "\n",
    "ham = random.choice(os.listdir(\"./easy_ham/\"))\n",
    "spam = random.choice(os.listdir(\"./spam/\"))\n",
    "\n",
    "#print(fetch_format(f\"./spam/{spam}\"))\n",
    "print(fetch_format(f\"./easy_ham/{ham}\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 1.1:\n",
    "It seems feasible to classify the emails only from inspection. It seems like a lot of spam mails contains words like \"invest\", \"click\" and \"100%\" etcetera. To create a model for this we could generate some statistics on which words often appear in spam mails but seldom in ham mails. Then we would know which words to look for. Looking through a mail we could generate a score based on how many of these words appear and taking into account how statistically probable they are to be in a spam mail. Another thing to look for is HTML tags. It seems a lot of spam mails contains HTML whereas ham mails doesn't. Simply looking for HTML-tags would suffice for this since that is needed for any HTML to work. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Note that the email files contain a lot of extra information, besides the actual message. Ignore that for now and run on the entire text (in the optional part further down can experiment with filtering out the headers and footers). We don’t want to train and test on the same data (it might help to reflect on why if you don't recall). Split the spam and the ham datasets in a training set and a test set. (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`). Use only the easy_ham part as ham data for quesions 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for here for splitting the data\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ham_paths = os.listdir(\"./easy_ham/\")\n",
    "spam_paths = os.listdir(\"./spam/\")\n",
    "\n",
    "ham = [fetch_format(f\"./easy_ham/{x}\") for x in ham_paths]\n",
    "hamlabels = [0 for x in ham_paths]\n",
    "spam = [fetch_format(f\"./spam/{x}\") for x in spam_paths]\n",
    "spamlabels = [1 for x in spam_paths]\n",
    "\n",
    "# Create dataframes for ham and spam with labels \"content\" \"label\"\n",
    "df_ham = pd.DataFrame(list(zip(ham, hamlabels)), columns=[\"content\", \"label\"])\n",
    "df_spam = pd.DataFrame(list(zip(spam, spamlabels)), columns=[\"content\", \"label\"])\n",
    "\n",
    "# Create one big dataframe for both ham and spam\n",
    "df = df_ham.append(df_spam)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Split data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"content\"], df[\"label\"], test_size=0.3) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "mnbrbI0_OKCF"
   },
   "source": [
    "### 2.1 Write a Python program that: \n",
    "1.\tUses the four datasets from Question 1 (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`) \n",
    "2.\tTrains a Naïve Bayes classifier (use the [scikit-learn library](https://scikit-learn.org/stable/)) on `hamtrain` and `spamtrain`, that classifies the test sets and reports True Positive and False Negative rates on the `hamtest` and `spamtest` datasets. Use `CountVectorizer` ([Documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer)) to transform the email texts into vectors. Please note that there are different types of Naïve Bayes Classifier in scikit-learn ([Documentation here](https://scikit-learn.org/stable/modules/naive_bayes.html)). Test two of these classifiers that are well suited for this problem:\n",
    "- Multinomial Naive Bayes  \n",
    "- Bernoulli Naive Bayes. \n",
    "\n",
    "Please inspect the documentation to ensure input to the classifiers is appropriate before you start coding. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "MJERHSCcGNaW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9748908296943232\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# Convert strings to word count\n",
    "vectorizer = CountVectorizer()\n",
    "vX_train = vectorizer.fit_transform(X_train)\n",
    "vX_test = vectorizer.transform(X_test)\n",
    "\n",
    "nb.fit(vX_train.toarray(), y_train)\n",
    "y_pred = nb.predict(vX_test.toarray())\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9006550218340611\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "nb = BernoulliNB()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vX_train = vectorizer.fit_transform(X_train)\n",
    "vX_test = vectorizer.transform(X_test)\n",
    "\n",
    "nb.fit(vX_train.toarray(), y_train)\n",
    "y_pred = nb.predict(vX_test.toarray())\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Answer the following questions:\n",
    "##### a) What does the CountVectorizer do?\n",
    "Answer 2.2.a\n",
    "\n",
    "CountVectorizer converts the contents of the emails (Strings) to a matrix of word counts, which is then used to categorize emails as spam or ham. each row corresponds to a document (email) and each column corresponds to a distinct word.\n",
    "\n",
    "##### b) What is the difference between Multinomial Naive Bayes and Bernoulli Naive Bayes?\n",
    "Answer 2.2.b\n",
    "\n",
    "MultinomialNB classifies an email based on the occurance of multiple keywords, whereas BinomialNB only counts one keyword. However BinomialNB also counts how many times the keyword does not appear in the email. In MultinomialNB, the frequency of each feature (word) is modeled using a multinomial distribution. BinomialBN is useful when classifying boolean attributes.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wDFS3uFFUcS7"
   },
   "source": [
    "### 3.1 Run the two models:\n",
    "Run (don't retrain) the two models from Question 2 on spam versus hard-ham. Does the performance differ compared to question 2 when the model was run on spam versus easy-ham? If so, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "gool_zb8Qzzy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8716814159292036\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "hard_ham_paths = os.listdir(\"./hard_ham/\")\n",
    "\n",
    "# Same procedure as previous task but this time we use \"hard_ham\" directory instead of \"easy_ham\"\n",
    "hard_ham = [fetch_format(f\"./hard_ham/{x}\") for x in hard_ham_paths]\n",
    "hard_hamlabels = [0 for x in hard_ham_paths]\n",
    "\n",
    "df_hard_ham = pd.DataFrame(list(zip(hard_ham, hard_hamlabels)), columns=[\"content\", \"label\"])\n",
    "\n",
    "df = df_hard_ham.append(df_spam)\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"content\"], df[\"label\"], test_size=0.3)\n",
    "\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vX_train = vectorizer.fit_transform(X_train)\n",
    "vX_test = vectorizer.transform(X_test)\n",
    "\n",
    "nb.fit(vX_train.toarray(), y_train)\n",
    "y_pred = nb.predict(vX_test.toarray())\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8672566371681416\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vX_train = vectorizer.fit_transform(X_train)\n",
    "vX_test = vectorizer.transform(X_test)\n",
    "\n",
    "nb.fit(vX_train.toarray(), y_train)\n",
    "y_pred = nb.predict(vX_test.toarray())\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3.1:\n",
    "\n",
    "The accuracy decreases for both MultinomialNB and BernoulliNB when using the \"hard_ham\" path. This is reasonable since these emails are harder to differentiate (more similar content to spam emails)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Retrain\n",
    "Retrain new Multinomial and Bernolli Naive Bayes classifers on the combined (easy+hard) ham and spam. Now evaluate on spam versus hard-ham as in 3.1. Also evaluate on spam versus easy-ham. Compare the performance with question 2 and 3.1. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9656912209889001\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "# Create big datafram with \"easy_ham\", \"hard_ham\" and \"spam\"\n",
    "df = df_ham.append([df_hard_ham, df_spam])\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"content\"], df[\"label\"], test_size=0.3)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vX_train = vectorizer.fit_transform(X_train)\n",
    "vX_test = vectorizer.transform(X_test)\n",
    "\n",
    "nb.fit(vX_train.toarray(), y_train)\n",
    "y_pred = nb.predict(vX_test.toarray())\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8849646821392533\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vX_train = vectorizer.fit_transform(X_train)\n",
    "vX_test = vectorizer.transform(X_test)\n",
    "\n",
    "nb.fit(vX_train.toarray(), y_train)\n",
    "y_pred = nb.predict(vX_test.toarray())\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3.2:\n",
    "\n",
    "The accuracy is somewhat similar to that of exercise 2.1, this may be due to the larger training dataset compared to excercise 2.1 and 3.1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Further improvements\n",
    "Do you have any suggestions for how performance could be further improved? You don't have to implement them, just present your ideas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer 3.3:\n",
    "\n",
    "- One could filter the emails better. In some emails data such as date and URLs are included in the content and word counts may be scewed which effects the performance of the classification.\n",
    "\n",
    "- The increasing the size of the dataset can increase the accuracy as seen in exercise 3.2.\n",
    "\n",
    "- Changing parameters such as alpha for the model can have an impact on the classifiaction accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "75df9f73f605be1caca45e667bef8c70565b1e5682af74864e8b0867b6079d60"
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
